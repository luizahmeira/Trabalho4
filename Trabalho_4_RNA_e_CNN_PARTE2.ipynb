{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KipUZZtyTYIy"
      },
      "source": [
        "# **Redes Neurais e CNN: Identificação de Objetos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjiEkS5gUJrq"
      },
      "source": [
        "Neste trabalho iremos fazer a identificação de um conjunto de dados de imagens de artigos de Zalando chamado Fashion-MNIST, que consiste em um conjunto de treinamento de 60.000 exemplos e um conjunto de teste de 10.000 exemplos. Cada exemplo é uma imagem em tons de cinza 28x28, associada a um rótulo de 10 classes.\n",
        "\n",
        "Fonte: https://www.tensorflow.org/datasets/catalog/fashion_mnist?hl=pt-br"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ass6OdNXC8M"
      },
      "source": [
        "# **ATIVIDADE:**\n",
        "\n",
        "**Descrição:**\n",
        "\n",
        "Nesta atividade, você receberá um código de uma Rede Neural Artificial e uma Rede Neural Convolucional (CNN) implementada. Sua tarefa é analisar o código fornecido e fazer uma interpretação detalhada de cada linha, identificando e explicando as principais etapas, camadas e operações realizadas pela RNA e pela CNN.\n",
        "\n",
        "**Instruções:**\n",
        "\n",
        "1. Preencha o código com comentários em cada linha, explicando sua função e propósito.\n",
        "2. Analise o código cuidadosamente para entender como a CNN é configurada.\n",
        "3. Identifique e explique as camadas de convolução, camadas de pooling, camadas densas, funções de ativação, tamanhos dos filtros, número de neurônios, etc.\n",
        "4. Identifique quais técnicas de regularização ou otimização formam utilizadas no código e explique como elas contribuem para o desempenho e a generalização do modelo.\n",
        "5. Comente sobre a função de ativação utilizada na camada de saída.\n",
        "6. Descreva os hiperparâmetros e ajustes do modelo, como a taxa de aprendizado, número de épocas de treinamento e o tratamento dos conjuntos de dados de treinamento e teste.\n",
        "7. Faça uma avaliação descritiva dos resultados das Redes Neurais implementadas.\n",
        "\n",
        "\n",
        "\n",
        "**Entregável:**\n",
        "\n",
        "Prepare uma análise detalhada do código fornecido, destacando as principais características da CNN e como ela é configurada para a tarefa em questão. Se necessário, inclua observações sobre o potencial de melhoria ou otimização do modelo.\n",
        "\n",
        "Esta atividade visa consolidar seu conhecimento sobre CNNs, ajudando a compreender como uma Rede Neural Convolucional é implementada e configurada para tarefas específicas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohTl6Xp6LuJs"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "importando o tensorflow e o keras\n",
        "'''\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FcIBZhXLuJt"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "importando mais algumas bibliotecas para auxiliar no desenvolvimento do trabalho\n",
        "'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adqNGOKbLuJu"
      },
      "source": [
        "## Importando base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JlM4b_QLuJu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Aqui acessamos o dataset Fashion MNIST que já está incluso no Keras\n",
        "o fashion_mnist é um conjunto de dados que vai ser usado para treinar e testar sistemas de aprendizado de máquina\n",
        "'''\n",
        "fashion_mnist = keras.datasets.fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5VmgIppLuJv"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Carregamento dos dados do fashion_mnist para a memória\n",
        "e separação desses dados em dados de treino e dados de teste\n",
        "'''\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaEdFh0WLuJv"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Printando os formatos dos dados de treino e teste\n",
        "'''\n",
        "print(X_train_full.shape)\n",
        "print(y_train_full.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP10-ncGLuJv"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Criação de um conjunto de validação a partir dos dados de treino\n",
        "e normalização dos dados para que os valores fiquem entre 0 e 1\n",
        "O código pega os primeiros 5000 exemplos do conjunto de treino para serem usados como validação\n",
        "e o restante como conjunto de treino efetivo.\n",
        "Por fim a separação dos rotulos é feita da mesma forma \n",
        "'''\n",
        "# Transformar a escala para que os valores fiquem entre 0 e 1\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAoUtsIkLuJv"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Definindo o nome das classes do dataset fashion_mnist\n",
        "'''\n",
        "nomes_classes = [\"camisa/top\", \"calca\", \"casaco\", \"vestido\", \"jaqueta\",\n",
        "               \"sandalia\", \"camiseta\", \"tenis\", \"bolsa\", \"bota\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR_2fLo-LuJv"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Acessa o sexto item do conjunto de treinamento e retorna o nome da classe correspondente\n",
        "'''\n",
        "nomes_classes[y_train[5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwh2gxu9LuJw"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Acessa o sexto item do conjunto de teste\n",
        "'''\n",
        "X_train[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZVGsmUDLuJw"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Definindo uma variável auxilicar para mostrar um exemplo do conjunto de treinamento\n",
        "printa o nome da classe correspondente e mostra a imagem usando o matplotlib\n",
        "é usado o nearest que significa que a imagem não será suavizada\n",
        "'''\n",
        "exemplo_n = 5\n",
        "print(nomes_classes[y_train[exemplo_n]])\n",
        "plt.imshow(X_train[exemplo_n], interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ixdiQPDLuJw"
      },
      "source": [
        "#  Rede Neural Artificial com Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBZRAsYaLuJw"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Definindo uma RNA sequencial com camadas densas e dropout para evitar overfitting\n",
        "Começa \"achatando\" a imagem 2D em um vetor único com a camada flatten\n",
        "Depois ele empilha duas camadas ocultas densas com 300 e 100 neurônios que usam \n",
        "a função relu pra processar os dados, intercaladas com camadas de dropout 10%\n",
        "que servem para desligar neurônios aleatórios e forçar a rede a aprender para que ela\n",
        "não decore os exemplos\n",
        "A rede termina com uma camada de saída de 10 neurônios usando softmax, responsável por\n",
        "calcular a probabilidade final para cada uma das 10 categorias de roupas\n",
        "então o summary() exibe um relatório com a estrutura criada\n",
        "'''\n",
        "\n",
        "nn = keras.models.Sequential()\n",
        "nn.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "nn.add(keras.layers.Dense(300, activation=\"relu\"))\n",
        "nn.add(keras.layers.Dropout(rate=0.1))\n",
        "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "nn.add(keras.layers.Dropout(rate=0.1))\n",
        "nn.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stsKAXBTLuJx"
      },
      "source": [
        "### Compilando e treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfTozWbnLuJx"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "configura e inicia o processo de aprendizado da rede\n",
        "o comando %time serve como um cronômetro para medir a duração da execução\n",
        "o método .compile() define a estratégia de estudo\n",
        "ele escolhe a função de perda para calcular o erro da rede\n",
        "define o otimizador sgd que vai ser usado para ajustar os pesos e corrigir esses erros\n",
        "e determina monitorando a taxa de accuracy.\n",
        "fit faz o treinamento usando os dados de validação (X_valid, y_valid) \n",
        "ao final de cada ciclo para testar se o aprendizado está realmente funcionando em dados novos\n",
        "e é tudo salvo na variaável history_nn\n",
        "'''\n",
        "\n",
        "%time\n",
        "nn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_nn = nn.fit(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be1X1Je8eTff"
      },
      "source": [
        "### Visualizar a performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHwnv3EseUkP"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Análise visual dos dados de treino com o plt\n",
        "'''\n",
        "pd.DataFrame(history_nn.history).plot(figsize=(12, 8))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19B6NqclLuJx"
      },
      "source": [
        "### Avaliar o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka4r9YLWLuJx"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Executando a avaliação final da rede usando os dados de teste\n",
        "exibe o erro final (loss) e a porcentagem de acertos\n",
        "servindo como a a nota do desempenho do modelo\n",
        "'''\n",
        "# prints the loss and the accuracy\n",
        "nn.evaluate(X_test, y_test,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsCurYbOexqi"
      },
      "source": [
        "###Realizar uma Previsão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsYS-xfFe3Iv"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "realiza uma simulação de previsão com o modelo já treinado\n",
        "primeiro ele seleciona as quatro primeiras imagens do conjunto de teste para servirem como dados novos\n",
        "depois o método .predict() faz a rede analisar essas imagens e armazena o resultado em y_proba\n",
        "'''\n",
        "X_novo = X_test[:4]\n",
        "y_proba = nn.predict(X_novo)\n",
        "y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt6c0pFGe6-I"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "analisa as porcentagens geradas anteriormente e seleciona o vencedor para cada imagem\n",
        "ele identifica o índice da categoria que obteve a maior nota de confiança\n",
        "depois o código imprime as classes e na última linha usa esses números como índices para buscar\n",
        "e imprimir os nomes reais das roupas na lista de classes\n",
        "'''\n",
        "y_pred = np.argmax(nn.predict(X_novo), axis=-1)\n",
        "print(y_pred)\n",
        "print(np.array(nomes_classes)[y_pred])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF4oMeAie9PZ"
      },
      "source": [
        "### Verificar os resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfnX_KyjfGYN"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Este trecho serve como o gabarito para verificar se a rede acertou\n",
        "ele isola as respostas certas das quatro imagens analisadas e salva em y_novo\n",
        "imprimindo esses códigos numéricos na tela\n",
        "a última linha pega as previsões que o modelo fez (y_pred) e exibe os nomes correspondentes \n",
        "'''\n",
        "y_novo = y_test[:4]\n",
        "print(y_novo)\n",
        "np.array(nomes_classes)[y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPI45glHfITC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "seleciona a terceira imagem do grupo de teste e imprime no console o nome da classe que\n",
        "a rede acredita ser a correta, depois ele exibe a imagem real correspondente na tela\n",
        "'''\n",
        "# example_n = 201\n",
        "print(nomes_classes[y_pred[2]])\n",
        "plt.imshow(X_novo[2], interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA9PAIkXLuJx"
      },
      "source": [
        "# Treinando CNN com Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlAbxJaoLuJx"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "construção da CNN\n",
        "começa definindo uma InputLayer explícita para imagens 28x28 em escala de cinza\n",
        "depois inicia a extração de características por empilhamento\n",
        "usando camadas de convolução para detectar padrões\n",
        "seguidas de MaxPool2D para reduzir o tamanho da imagem e focar no que importa\n",
        "aumentando progressivamente o valor dos filtros, que permite a rede aprender \n",
        "desde traços simples até formas complexas\n",
        "o padding='same' faz com que a imagem não diminua de tamanho nas bordas durante as convoluções\n",
        "'''\n",
        "cnn = keras.models.Sequential([\n",
        "keras.layers.InputLayer(input_shape = (28,28,1)),\n",
        "keras.layers.Conv2D(64,5, activation='relu', padding='same', kernel_initializer='glorot_uniform'),\n",
        "keras.layers.MaxPool2D(2),\n",
        "keras.layers.Conv2D(128,3, activation='relu', padding='same'),\n",
        "keras.layers.Conv2D(128,3, activation='relu', padding='same'),\n",
        "keras.layers.MaxPool2D(2),\n",
        "keras.layers.Conv2D(258,3, activation='relu', padding='same'),\n",
        "keras.layers.Conv2D(258,3, activation='relu', padding='same'),\n",
        "keras.layers.MaxPool2D(2),\n",
        "keras.layers.Flatten(),\n",
        "keras.layers.Dense(128, activation=\"relu\"),\n",
        "keras.layers.Dropout(rate=0.5),\n",
        "keras.layers.Dense(64, activation=\"relu\"),\n",
        "keras.layers.Dropout(rate=0.5),\n",
        "keras.layers.Dense(10, activation=\"softmax\")])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxw6_5HMLuJx"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Gera um relatório da estrutura da CNN criada\n",
        "'''\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEhTE1mVLuJx"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "responsável por adaptar o formato dos dados para que eles caibam na entrada da CNN\n",
        "as camadas convolucionais precisam que os dados tenham 4 dimensões\n",
        "(Quantidade de Imagens, Altura, Largura, Canais de Cor)\n",
        "mas o dataset é carregado com 3 dimensões \n",
        "pra resolver isso é usado o .reshape() para adicionar o número 1 ao final das matrizes de treino\n",
        "validação e teste\n",
        "isso transforma o formato dos dados de (N, 28, 28) para (N, 28, 28, 1)\n",
        "indicando que existe 1 canal de cor (preto e branco)\n",
        "'''\n",
        "print(X_train.shape)\n",
        "X_train_new = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2],1)\n",
        "X_valid_new = X_valid.reshape(X_valid.shape[0], X_valid.shape[1], X_valid.shape[2],1)\n",
        "X_test_new = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2],1)\n",
        "print(X_train_new.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr80opDHLuJx"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "responsável por configurar as regras de aprendizado e dar a partida no treinamento da CNN\n",
        "define a estratégia,  usando a função de perda sparse_categorical_crossentropy\n",
        "escolhe o otimizador sgd para ajustar os pesos internos e foca na accuracy para medir o sucesso\n",
        ".fit() treina o modelo usando os dados já redimensionados com o canal de cor\n",
        "rodando por 20 epocas enquanto valida o desempenho passo a passo usando o conjunto de validação também ajustado (X_valid_new)\n",
        "'''\n",
        "cnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_cnn = cnn.fit(X_train_new, y_train, epochs=20, validation_data=(X_valid_new, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1LzINmFLuJy"
      },
      "source": [
        "### Avaliar o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xV2EgWCLuJy"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "faz a avaliação final de desempenho da CNN\n",
        "'''\n",
        "cnn.evaluate(X_test_new, y_test,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrT2Xba5LuJy"
      },
      "outputs": [],
      "source": [
        "'''Este trecho gera o gráfico de desempenho da CNN ao longo das 20 épocas de treinamento'''\n",
        "pd.DataFrame(history_cnn.history).plot(figsize=(12, 8))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
